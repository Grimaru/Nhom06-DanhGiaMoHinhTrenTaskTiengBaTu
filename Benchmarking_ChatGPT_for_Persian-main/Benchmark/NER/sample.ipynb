{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Given a sample"
      ],
      "metadata": {
        "id": "0Hxd5Q7B-BAw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sDE9R-pWy6sk"
      },
      "outputs": [],
      "source": [
        "sample = {\"input\":\"\\n  ['این', 'اولین', 'قرارداد', 'میان', 'شرکت', 'ملی', 'نفت', 'چین', 'با', 'ایران', 'از', 'هنگام', 'پیروزی', 'انقلاب', 'اسلامی', 'است', '.']\\n  \",\"output\":\"[('این', 'O'), ('اولین', 'O'), ('قرارداد', 'O'), ('میان', 'O'), ('شرکت', 'ORG'), ('ملی', 'ORG'), ('نفت', 'ORG'), ('چین', 'ORG'), ('با', 'O'), ('ایران', 'LOC'), ('از', 'O'), ('هنگام', 'O'), ('پیروزی', 'O'), ('انقلاب', 'O'), ('اسلامی', 'O'), ('است', 'O'), ('.', 'O')]\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare input prompt"
      ],
      "metadata": {
        "id": "G8djB1Hn-beR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt import ENGLISH_ONE"
      ],
      "metadata": {
        "id": "7kxKSiuu-bEX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt = ENGLISH_ONE.format(input=sample['input'])"
      ],
      "metadata": {
        "id": "2TBmTh6f-j6I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLyTcM60-s1o",
        "outputId": "707f0d35-3157-4c20-d409-96a37f9db8a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Task Description:\n",
            "  You need to label a given Persian token list with named entity labels.\n",
            "  Named Entity Labels:\n",
            "\n",
            "  PER (person)\n",
            "  LOC (location)\n",
            "  ORG (organization)\n",
            "  Product (Product)\n",
            "  Event (Event)\n",
            "  Facility (Facility)\n",
            "\n",
            "  Here, we provide you examples of the task:\n",
            "    \n",
            "\n",
            "  Example 1:\n",
            "      Input: ['حمید', 'طاهایی', 'افزود', ':', 'برای', 'اجرای', 'این', 'طرحها', '0', 'میلیارد', 'و', '0', 'میلیون', 'ریال', 'اعتبار', 'هزینه', 'شده', 'است', '.']\n",
            "      Output: [('حمید', 'PER'), ('طاهایی', 'PER'), ('افزود', 'O'), (':', 'O'), ('برای', 'O'), ('اجرای', 'O'), ('این', 'O'), ('طرحها', 'O'), ('0', 'O'), ('میلیارد', 'O'), ('و', 'O'), ('0', 'O'), ('میلیون', 'O'), ('ریال', 'O'), ('اعتبار', 'O'), ('هزینه', 'O'), ('شده', 'O'), ('است', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 2:\n",
            "      Input: ['جشنواره', 'فیلم', 'دفاع', 'مقدس', 'از', '0', 'تا', '0', 'مهرماه', 'در', 'چهار', 'سینمای', 'تهران', 'و', 'فرهنگسرای', 'نیاوران', 'و', 'بهمن', 'بر', 'پا', 'می‌شود', '.']\n",
            "      Output: [('جشنواره', 'Event'), ('فیلم', 'Event'), ('دفاع', 'Event'), ('مقدس', 'Event'), ('از', 'O'), ('0', 'O'), ('تا', 'O'), ('0', 'O'), ('مهرماه', 'O'), ('در', 'O'), ('چهار', 'O'), ('سینمای', 'O'), ('تهران', 'LOC'), ('و', 'O'), ('فرهنگسرای', 'Facility'), ('نیاوران', 'Facility'), ('و', 'O'), ('بهمن', 'Facility'), ('بر', 'O'), ('پا', 'O'), ('می‌شود', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 3:\n",
            "      Input: ['ایرن', 'ژاکوب', '،', 'هنرپیشه', 'فرانسوی', 'نیز', 'قرار', 'است', 'در', 'این', 'تئاتر', 'نقش', 'مقابل', 'کالکین', 'را', 'به', 'عهده', 'بگیرد', '.']\n",
            "      Output: [('ایرن', 'PER'), ('ژاکوب', 'PER'), ('،', 'O'), ('هنرپیشه', 'O'), ('فرانسوی', 'ORG'), ('نیز', 'O'), ('قرار', 'O'), ('است', 'O'), ('در', 'O'), ('این', 'O'), ('تئاتر', 'O'), ('نقش', 'O'), ('مقابل', 'O'), ('کالکین', 'PER'), ('را', 'O'), ('به', 'O'), ('عهده', 'O'), ('بگیرد', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 4:\n",
            "      Input: ['برنامه', 'موسیقی', 'دوتارنوازی', 'به', 'معرفی', 'موسیقی', 'تربت‌جام', 'از', 'خطه', 'خراسان', 'می‌پردازد', '.']\n",
            "      Output: [('برنامه', 'O'), ('موسیقی', 'O'), ('دوتارنوازی', 'O'), ('به', 'O'), ('معرفی', 'O'), ('موسیقی', 'O'), ('تربت‌جام', 'LOC'), ('از', 'O'), ('خطه', 'O'), ('خراسان', 'LOC'), ('می‌پردازد', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 5:\n",
            "      Input: ['رومئو', 'و', 'ژولیت', 'تمدید', 'شد', '.']\n",
            "      Output: [('رومئو', 'Product'), ('و', 'Product'), ('ژولیت', 'Product'), ('تمدید', 'O'), ('شد', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 6:\n",
            "      Input: ['تامسون', 'كه', '0', 'سال', 'دارد', '،', 'در', 'فیلم', 'آرزوهای', 'بزرگ', '،', 'برگرفته', 'از', 'رمان', 'چارلز', 'دیکنز', 'بازی', 'کرده', 'است', '.']\n",
            "      Output: [('تامسون', 'PER'), ('كه', 'O'), ('0', 'O'), ('سال', 'O'), ('دارد', 'O'), ('،', 'O'), ('در', 'O'), ('فیلم', 'Product'), ('آرزوهای', 'Product'), ('بزرگ', 'Product'), ('،', 'O'), ('برگرفته', 'O'), ('از', 'O'), ('رمان', 'O'), ('چارلز', 'PER'), ('دیکنز', 'PER'), ('بازی', 'O'), ('کرده', 'O'), ('است', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Example 7:\n",
            "      Input: ['رئیس', 'قوه', 'قضائیه', ':', 'درباره', 'مجازات', 'زندان', 'باید', 'تحولاتی', 'به', 'وجود', 'آید', '.']\n",
            "      Output: [('رئیس', 'O'), ('قوه', 'ORG'), ('قضائیه', 'ORG'), (':', 'O'), ('درباره', 'O'), ('مجازات', 'O'), ('زندان', 'O'), ('باید', 'O'), ('تحولاتی', 'O'), ('به', 'O'), ('وجود', 'O'), ('آید', 'O'), ('.', 'O')]\n",
            "\n",
            "  \n",
            "\n",
            "  Output Format:\n",
            "  Your output format should be a list of tuples, where each tuple consists of a word from the input text and its corresponding named entity label.\n",
            "  For words which are not part of any named entity, you should return 'O'.\n",
            "\n",
            "  Input:\n",
            "  \n",
            "  ['این', 'اولین', 'قرارداد', 'میان', 'شرکت', 'ملی', 'نفت', 'چین', 'با', 'ایران', 'از', 'هنگام', 'پیروزی', 'انقلاب', 'اسلامی', 'است', '.']\n",
            "  \n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model's response"
      ],
      "metadata": {
        "id": "LAN89Jzy-02_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_GPT_response = \"\"\"[('این', 'O'), ('اولین', 'O'), ('قرارداد', 'O'), ('میان', 'O'), ('شرکت', 'O'), ('ملی', 'ORG'), ('نفت', 'ORG'), ('چین', 'LOC'), ('با', 'O'), ('ایران', 'LOC'), ('از', 'O'), ('هنگام', 'O'), ('پیروزی', 'O'), ('انقلاب', 'O'), ('اسلامی', 'Event'), ('است', 'O'), ('.', 'O')]\"\"\""
      ],
      "metadata": {
        "id": "enTpaKsm-4mo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [\"O\", 'PER', 'person', 'LOC', 'location', 'ORG', 'organization', 'Product', 'Event', 'Facility', \"I-event\", \"I-fac\", \"I-loc\", \"I-org\", \"I-pers\", \"I-pro\", \"B-event\", \"B-fac\", \"B-loc\", \"B-org\", \"B-pers\", \"B-pro\"]\n",
        "tags_2_i = {v:i for i,v in enumerate(tags)}\n",
        "i_2_tags = {i:v for i,v in enumerate(tags)}"
      ],
      "metadata": {
        "id": "o90bejZH_YjV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_2_list(l12):\n",
        "  l1 = l12[l12.index('['):]\n",
        "  # print(l1)\n",
        "  if (l1[0] != '[' or l1[-1] != ']') and len(l1) > 2:\n",
        "    return [('گفت', 'O')]\n",
        "  l1 = l1.replace('...',\"', ''\")\n",
        "  l1 = l1.replace('\\'',\"\\\"\")\n",
        "  # print(l1)\n",
        "  res = l1.strip('][').split(', ')\n",
        "  out = []\n",
        "  for i in range(0,len(res)-1,2):\n",
        "    a = res[i].replace('\\\"','')\n",
        "    a = a.replace('(','')\n",
        "    a = a.replace(')','')\n",
        "    b = res[i+1].replace('\\\"','')\n",
        "    b = b.replace('(','')\n",
        "    b = b.replace(')','')\n",
        "    out.append((a,b))\n",
        "  return out\n",
        "convert_2_list(\"[('یکی', 'O'), ('از', 'O'), ('نمایندگان', 'O'), ('در', 'O'), ('این', 'O'), ('خصوص', 'O'), ('به', 'O'), ('خبرنگار', 'O'), ('ما', 'O'), ('گفت', 'O'), (':', 'O'), ('بیشترین', 'O'), ('نگرانی\\u200cها', 'O'), ('مربوط', 'O'), ('به', 'O'), ('بازداشتگاه\\u200cها', 'O'), ('است', 'O'), ('.', 'O')]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzensrb1_Z5o",
        "outputId": "1e9f081c-971b-446d-fb7e-a88887ea52e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('یکی', 'O'),\n",
              " ('از', 'O'),\n",
              " ('نمایندگان', 'O'),\n",
              " ('در', 'O'),\n",
              " ('این', 'O'),\n",
              " ('خصوص', 'O'),\n",
              " ('به', 'O'),\n",
              " ('خبرنگار', 'O'),\n",
              " ('ما', 'O'),\n",
              " ('گفت', 'O'),\n",
              " (':', 'O'),\n",
              " ('بیشترین', 'O'),\n",
              " ('نگرانی\\u200cها', 'O'),\n",
              " ('مربوط', 'O'),\n",
              " ('به', 'O'),\n",
              " ('بازداشتگاه\\u200cها', 'O'),\n",
              " ('است', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findstem(arr):\n",
        "\n",
        "    # Determine size of the array\n",
        "    n = len(arr)\n",
        "\n",
        "    # Take first word from array\n",
        "    # as reference\n",
        "    s = arr[0]\n",
        "    l = len(s)\n",
        "\n",
        "    res = \"\"\n",
        "\n",
        "    for i in range(l):\n",
        "        for j in range(i + 1, l + 1):\n",
        "\n",
        "            # generating all possible substrings\n",
        "            # of our reference string arr[0] i.e s\n",
        "            stem = s[i:j]\n",
        "            k = 1\n",
        "            for k in range(1, n):\n",
        "\n",
        "                # Check if the generated stem is\n",
        "                # common to all words\n",
        "                if stem not in arr[k]:\n",
        "                    break\n",
        "\n",
        "            # If current substring is present in\n",
        "            # all strings and its length is greater\n",
        "            # than current result\n",
        "            if (k + 1 == n and len(res) < len(stem)):\n",
        "                res = stem\n",
        "\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "0RzDvTzf_6jY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparable_gold_pred2(res, ls, ts):\n",
        "  # print(res)\n",
        "  # print(ts)\n",
        "  # print([i_2_tags[i] for i in ls])\n",
        "  i2l = [i_2_tags[i] for i in ls]\n",
        "  for i, v in enumerate(ts):\n",
        "    # print(v)\n",
        "    # if i < len(res):\n",
        "      # print(res[i])\n",
        "    # else:\n",
        "    #   res.append((\"\", ''))\n",
        "    if i >= len(res):\n",
        "      res.append((\"\", ''))\n",
        "      # print(res[i])\n",
        "    # print(i2l[i])\n",
        "    # print(res[i][0].replace(\"\\\\u200c\",\" \"), ts[i].replace(\"\\u200c\",\" \"))\n",
        "    # print('dataset', ts[i].replace(\"\\u200c\",\" \").lower())\n",
        "    # print('result', res[i][0].replace(\"\\\\u200c\",\" \").lower())\n",
        "    # print('stem', findstem([res[i][0].replace(\"\\\\u200c\",\" \").lower(), ts[i].replace(\"\\u200c\",\" \").lower()]))\n",
        "    if findstem([res[i][0].replace(\"\\\\u200c\",\" \").lower(), ts[i].replace(\"\\u200c\",\" \").lower()]) == ts[i].replace(\"\\u200c\",\" \").lower():\n",
        "      if res[i][1].lower() in i2l[i].lower():\n",
        "        # print(i, 'match', i2l[i], 'word', ts[i])\n",
        "        tempi = list(res[i])\n",
        "        tempi[1] = i2l[i]\n",
        "        res[i] = tuple(tempi)\n",
        "    else:\n",
        "      # print('yyyyyy')\n",
        "      # print(res, i2l)\n",
        "      tempi = list(res[i])\n",
        "      tempi[1] = 'O'\n",
        "      res[i] = tuple(tempi)\n",
        "      continue\n",
        "  # print('res len', len(res), 'inp len', len(ts), 'labels len', len(ls))\n",
        "  # print([i[1] for i in res])\n",
        "  # print(i2l)\n",
        "  for i,v in enumerate(res):\n",
        "    # print(v, len(i2l), i)\n",
        "    if i >= len(i2l):\n",
        "      break\n",
        "    if v[1] != i2l[i] and not v[1] in tags:\n",
        "      for k,j in enumerate(tags):\n",
        "        if v[1].lower() in j.lower():\n",
        "          temp = list(res[i])\n",
        "          temp[1] = tags[k]\n",
        "          res[i] = tuple(temp)\n",
        "  return [i[1] for i in res], i2l"
      ],
      "metadata": {
        "id": "zZSmkafI_-Qc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gls = []\n",
        "pls = []\n",
        "\n",
        "ls = ['PER', 'person', 'LOC', 'location', 'ORG', 'organization', 'Product', 'Event', 'Facility']\n",
        "\n",
        "for i in range(1):\n",
        "\n",
        "  g = convert_2_list(sample['output'])\n",
        "  p = convert_2_list(sample_GPT_response)\n",
        "\n",
        "  pl, gl = comparable_gold_pred2(p, [(tags_2_i[i[1]] if i[1] in ls else tags_2_i['O'])  for i in g], [i[0] for i in g])\n",
        "  print(pl, gl, [i[0] for i in g])\n",
        "  gls.extend([(i if i in ls else 'O') for i in gl])\n",
        "  pls.extend([(i if i in ls else 'O') for i in pl][:len(gl)])\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4vDCjL0ACrM",
        "outputId": "8e15849c-04a8-47a8-a4e2-60f57c79fd86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'LOC', 'O', 'LOC', 'O', 'O', 'O', 'O', 'Event', 'O', 'O'] ['O', 'O', 'O', 'O', 'ORG', 'ORG', 'ORG', 'ORG', 'O', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ['این', 'اولین', 'قرارداد', 'میان', 'شرکت', 'ملی', 'نفت', 'چین', 'با', 'ایران', 'از', 'هنگام', 'پیروزی', 'انقلاب', 'اسلامی', 'است', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goi = []\n",
        "pri = []\n",
        "\n",
        "for i in gls:\n",
        "  goi.append(tags_2_i[i])\n",
        "\n",
        "for i in pls:\n",
        "  pri.append(tags_2_i[i])"
      ],
      "metadata": {
        "id": "xocr_UGUAgFe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(goi, pri, target_names=[tags[i] for i in set(goi).union(set(pri))], digits=6)) #target_names=[tags[i] for i in [0,1,3,5,7,8,9]],"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDYI1NPcAnLo",
        "outputId": "5ba39e45-be53-4e33-dcaf-5b387807d4c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O   1.000000  0.916667  0.956522        12\n",
            "         LOC   0.500000  1.000000  0.666667         1\n",
            "         ORG   1.000000  0.750000  0.857143         4\n",
            "       Event   0.000000  0.000000  0.000000         0\n",
            "\n",
            "    accuracy                       0.882353        17\n",
            "   macro avg   0.625000  0.666667  0.620083        17\n",
            "weighted avg   0.970588  0.882353  0.916088        17\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}